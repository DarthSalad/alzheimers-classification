{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import itertools\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "test_dir = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/test/\"\n",
    "train_dir = \"/kaggle/input/alzheimers-dataset-4-class-of-images/Alzheimer_s Dataset/train/\"\n",
    "\n",
    "data = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the input paths for the Kaggle dataset and the output path for the trained model.\n",
    "We also initialize an empty list to store the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirtrain in os.listdir(train_dir): \n",
    "    print(dirtrain)\n",
    "    for tr in os.listdir(train_dir + dirtrain):\n",
    "        img = cv2.imread(train_dir + dirtrain + \"/\" + tr)\n",
    "        img = cv2.resize(img, (32, 32))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = img.reshape(32, 32, 1)\n",
    "        \n",
    "        data.append([img, dirtrain])        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each iteration we:\n",
    "- read image\n",
    "- resize the image to matrix of 32x32\n",
    "- grayscaling image\n",
    "- reshape the image to 3D with one color channel (Gray)\n",
    "- append each image with label to the data list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirtest in  os.listdir(test_dir):    \n",
    "    print(dirtest)\n",
    "    for ts in os.listdir(test_dir + dirtest):\n",
    "        img = cv2.imread(test_dir + dirtest + \"/\" + ts)\n",
    "        img = cv2.resize(img, (32, 32))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = img.reshape(32, 32, 1)\n",
    "        \n",
    "        data.append([img, dirtest])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then shuffle the data randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = [], []\n",
    "for e in data:\n",
    "    x.append(e[0])\n",
    "    y.append(e[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data to images in a list and labels in another list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "y = y.reshape(y.shape[0],1)\n",
    "enc = OneHotEncoder(handle_unknown='ignore').fit(y)\n",
    "print(enc.categories_)\n",
    "y = enc.transform(y).toarray()\n",
    "print(f'Data   :   {str(x.shape)}')\n",
    "print(f'Labels :   {str(y.shape)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode the labels using one-hot encoding. The encoder creates a new column for each label and assigns a 1 or 0 to the column. This is to avoid the model to assume a natural ordering between categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=1, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split the data into training and validation sets. We use 80% of the data for training and 20% for validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the GPU to accelerate the training process. We are running the notebook on Kaggle for training and prediction so the GPU are listed from Kaggle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (4, 4), padding='same', activation=tf.nn.relu, \n",
    "    input_shape=(32, 32, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)), Dropout(0.25),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (3,3), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (2,2), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    tf.keras.layers.Conv2D(256, (2,2), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2)),\n",
    "    Dropout(0.3),\n",
    "                    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(4,  activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above cell we define the model architecture. We use the Sequential model from Keras. The model is a stack of layers where each layer has exactly one input tensor and one output tensor. We use the following layers:\n",
    "- Conv2D: 2D convolution layer (e.g. spatial convolution over images).\n",
    "- MaxPooling2D: Max pooling operation for spatial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=True,\n",
    "    dpi=96,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now plot the model architecture. We can see the layers and the number of parameters in each layer. The number of parameters is the number of weights in each layer. The weights are the values that the model learns during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "hist = model.fit(x_train, y_train, epochs=100, validation_split=0.2, batch_size=64,verbose=1,shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start training the model with an epoch of 100. We use the Adam optimizer and the categorical crossentropy loss function. We also use the accuracy metric to measure the performance of the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=80)\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the loss of training. We can see that the loss is decreasing with each epoch. We can also see that the validation loss is decreasing with each epoch. This means that the model is not overfitting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6), dpi=80)\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot the accuracy of training. We can see that the accuracy is increasing with each epoch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test, verbose=2)\n",
    "y_pred = model.predict(x_test).argmax(axis=1)\n",
    "print(f'Test Loss     : {loss_and_metrics[0]}')\n",
    "print(f'Test Accuracy : {loss_and_metrics[1]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the labels of the validation set. We then calculate the accuracy of the model by comparing the predicted labels with the actual labels and print the accuracy and loss of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "df = pd.DataFrame(\n",
    "  data = metrics.confusion_matrix(np.argmax(y_test, axis=1), y_pred),\n",
    "  columns = ['0', '1', '2', '3'],\n",
    "  index = ['0', '1', '2', '3']\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(df, cmap=\"Reds\", annot=True, fmt='.0f')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot the confusion matrix. The confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data for which the true values are known. The confusion matrix itself is relatively simple to understand, but the related terminology can be confusing."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
